==========================================================================
kmeans Application Kernel User Guide
==========================================================================
# Author : Derek Lockhart 
# Date   : April 2010

The kmeans application kernel uses the kmeans algorithm to iteratively 
classify a collection of objects into K clusters.

The algorithm has several stages:

* stage 0: arbitrary examples are chosen as the initial cluster centers
* stage 1: examples are assigned to clusters by calculating their distance
           to each cluster centroid, the nearest cluster is chosen
* stage 2: new cluster centroids are computed 

This process is repeated until the cluster assignments stabilize. The
assignments are considered stable once the number of examples changing
cluster memberships drops below a user-provided threshold.

Pseudocode for the KMeans clustering algorithm is shown below.

 do:
   swap_count = 0
   # find the minimum distance cluster centroid 
   for ex in examples:
     for c in clusters:
       for attr in attributes:
         dist += (ex.attr - c.attr)^2
       # assign example to this cluster if its the nearest thus far
       if dist < min_dist
         min_dist = dist
         min_idx = c
     # increment the swap count if this example changed membership
     if min_idx != ex_2_cl[i]
       swap_count++
       ex_2_c[ex] = min_idx
   # recompute the location of each cluster centroid
   count[] = [0..0]
   c_new[] = [0..0]
   for ex in examples:
     c_new = ex_2_c[ex]
     for attr in attributes:
       c_new.attr += ex.attr
     # increment the count of examples assigned to this cluster
     count[c_new]++
   # normalize the centroid
   for c in clusters:
     for attr in attributes:
       c.attr /= count[c]
   # percentage of examples that changed membership   
   delta = swap_count/len(examples)
 # repeat if we didn't meet the threshold
 while (delta < threshold)

The MIMD and VT implementations parallelize across examples in Stage 1
of the KMeans algorithm. Computation of centroid distances and updating
the example-to-cluster mapping data structure is entirely data-parallel, 
however, an atomic increment operation is required to update the swap 
count used by threshold check. Alternatively, this could be implemented 
by keeping local swap counts and performing a reduce.

Stage 2 is also parallelized across examples, which leads to data-sharing
conflicts when two examples need to update the same cluster centroid.
Since this occurs quite frequently when the value of K is small, we
perform updates locally and then reduce in order to avoid using locks. 
The reduction phase of Stage 2 is parallelized across clusters.

An alternative implementation of Stage 2 (and the more obvious approach)
would be to directly parallelize across clusters. While this approach has
the advantage of avoiding conflicts due to data sharing, it is more 
susceptible to load imbalance if examples aren't distributed evenly 
across clusters.

Stage 0 is currently not parallelized, although it could be. Typically 
the value of K is fairly small, so this may not be very beneficial.
     
The dataset kmeans-color100.dat is borrowed from the implementation
provided by Wei-keng Liao at Northwestern.

References:

  http://www.eecs.northwestern.edu/~wkliao/Kmeans/index.html

